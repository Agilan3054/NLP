{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be5e4065-b260-4251-b970-229bda1cc02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Agilan M\n",
      "[nltk_data]     A\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b497cd-3a76-4409-9e09-c9380024e274",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sent = 'Harry Potter is coming to Hogwarts'\n",
    "cont_sent_token = wt(cont_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf095e4a-0da8-4814-a174-2da25ec2badb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harry', 'Potter', 'is', 'coming', 'to', 'Hogwarts']\n"
     ]
    }
   ],
   "source": [
    "print(cont_sent_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32a0789-9005-481f-a8b6-179572b2cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Agilan M A\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ac4568-fcda-49c5-943e-e4bf6b576c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sent_tag = nltk.pos_tag(cont_sent_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95aacb4c-fe21-4800-ba2d-8c67fea0433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Harry', 'NNP'), ('Potter', 'NNP'), ('is', 'VBZ'), ('coming', 'VBG'), ('to', 'TO'), ('Hogwarts', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "print(cont_sent_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31135131-caca-4bf2-926d-349eb5a533da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to C:\\Users\\Agilan M\n",
      "[nltk_data]     A\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping help\\tagsets.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db9e6427-3cee-4ead-8900-ee70658d6234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68554cd6-9970-44fa-bad5-a7301f6f5c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem.lemmatize(\"are\", pos=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d952ffa-8052-474d-9230-b671897907b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verb_to_wordnet(verb_tag):\n",
    "    if verb_tag.startswith('V') or verb_tag.startswith('JJ'):\n",
    "        return 'v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "345e0d2f-af19-4f85-bfd1-fe97cf777492",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_sent_lem = []\n",
    "for i in cont_sent_tag:\n",
    "    wordnet_verb = verb_to_wordnet(i[1])\n",
    "    \n",
    "    if wordnet_verb is not None:\n",
    "        cont_sent_lem.append(lem.lemmatize(i[0], wordnet_verb))\n",
    "    else:\n",
    "        cont_sent_lem.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb48ca29-8044-4ad7-a040-2c3f916fcd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harry', 'Potter', 'be', 'come', 'to', 'Hogwarts']\n"
     ]
    }
   ],
   "source": [
    "print(cont_sent_lem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c5dc725-ffec-452f-99f9-ac4884539461",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0;\n",
    "for i in range(len(cont_sent_lem)):\n",
    "    if cont_sent_lem[i]=='be':\n",
    "        index = i\n",
    "if 'not' in cont_sent_lem:\n",
    "    pos_neg = 'neg'\n",
    "else:\n",
    "    pos_neg = 'pos'\n",
    "if cont_sent_tag[index-1][1] == 'NN' or cont_sent_tag[index-1][1] == 'NNP' or cont_sent_tag[index-1][1] == 'JJ' or cont_sent_tag[index-1][0].capitalize() == 'He' or cont_sent_tag[index-1][0].capitalize() == 'She' or cont_sent_tag[index-1][0].capitalize() == 'It':\n",
    "    \n",
    "    if pos_neg == 'pos':\n",
    "        \n",
    "        if cont_sent_lem[index+1][-1] == 'o' or cont_sent_lem[index+1][-1] == 's' or cont_sent_lem[index+1][-1] == 'z' or cont_sent_lem[index+1][-2:] == 'ch' or cont_sent_lem[index+1][-2:] == 'sh' or cont_sent_lem[index+1][-1] == 'x':\n",
    "            cont_sent_lem[index+1]+='es'\n",
    "        \n",
    "        elif cont_sent_lem[index+1][-1] == 'y':\n",
    "            if cont_sent_lem[index+1][-2] == 'a' or cont_sent_lem[index+1][-2] == 'e' or cont_sent_lem[index+1][-2] == 'i' or cont_sent_lem[index+1][-2] == 'o' or cont_sent_lem[index+1][-2] == 'u':\n",
    "                cont_sent_lem[index+1]+='s'\n",
    "            else:\n",
    "                cont_sent_lem[index+1] = cont_sent_lem[index+1].replace(cont_sent_lem[index+1][-1],'ies')\n",
    "        \n",
    "        elif cont_sent_lem[index+1] == 'have':\n",
    "            cont_sent_lem[index+1] = cont_sent_lem[index+1].replace('have','has')\n",
    "        \n",
    "        else:\n",
    "            cont_sent_lem[index+1]+='s'\n",
    "            \n",
    "        cont_sent_lem.remove('be')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        cont_sent_lem = ['does' if word == 'be' else word for word in cont_sent_lem]\n",
    "        \n",
    "else:\n",
    "    if pos_neg == 'pos':\n",
    "        cont_sent_lem.remove('be')\n",
    "    else:\n",
    "        cont_sent_lem = ['do' if word == 'be' else word for word in cont_sent_lem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97d637bf-8261-4ece-adbb-f57ac418499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Harry', 'Potter', 'comes', 'to', 'Hogwarts']\n"
     ]
    }
   ],
   "source": [
    "print(cont_sent_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e822bea-10fb-4c34-ae63-2b397704c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter comes to Hogwarts\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(cont_sent_lem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f596bb3-2a6a-4119-a331-61933d65af56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Agilan M\n",
      "[nltk_data]     A\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af809809-a4bd-40bb-a0e1-dc8d71e9973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verb_to_wordnet(verb_tag):\n",
    "    if verb_tag.startswith('V') or verb_tag.startswith('JJ'):\n",
    "        return 'v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4bc0e2b-80ad-4413-947b-e371c2d30207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_singular_plural(cont_sent_tag, cont_sent_lem):\n",
    "    index = 0\n",
    "    for i in range(len(cont_sent_lem)):\n",
    "        if cont_sent_lem[i] == 'be':\n",
    "            index = i\n",
    "    if 'not' in cont_sent_lem:\n",
    "        pos_neg = 'neg'\n",
    "    else:\n",
    "        pos_neg = 'pos'\n",
    "    if cont_sent_tag[index - 1][1] == 'NN' or cont_sent_tag[index - 1][1] == 'NNP' or cont_sent_tag[index - 1][1] == 'JJ' or cont_sent_tag[index - 1][0].capitalize() == 'He' or cont_sent_tag[index - 1][0].capitalize() == 'She' or cont_sent_tag[index - 1][0].capitalize() == 'It':\n",
    "        if pos_neg == 'pos':\n",
    "            if cont_sent_lem[index + 1][-1] == 'o' or cont_sent_lem[index + 1][-1] == 's' or cont_sent_lem[index + 1][-1] == 'z' or cont_sent_lem[index + 1][-2:] == 'ch' or cont_sent_lem[index + 1][-2:] == 'sh' or cont_sent_lem[index + 1][-1] == 'x':\n",
    "                cont_sent_lem[index + 1] += 'es'\n",
    "            elif cont_sent_lem[index + 1][-1] == 'y':\n",
    "                if cont_sent_lem[index + 1][-2] in ['a', 'e', 'i', 'o', 'u']:\n",
    "                    cont_sent_lem[index + 1] += 's'\n",
    "                else:\n",
    "                    cont_sent_lem[index + 1] = cont_sent_lem[index + 1].replace(cont_sent_lem[index + 1][-1], 'ies')\n",
    "            elif cont_sent_lem[index + 1] == 'have':\n",
    "                cont_sent_lem[index + 1] = cont_sent_lem[index + 1].replace('have', 'has')\n",
    "            else:\n",
    "                cont_sent_lem[index + 1] += 's'\n",
    "            cont_sent_lem.remove('be')\n",
    "        else:\n",
    "            cont_sent_lem = ['does' if word == 'be' else word for word in cont_sent_lem]\n",
    "    else:\n",
    "        if pos_neg == 'pos':\n",
    "            cont_sent_lem.remove('be')\n",
    "        else:\n",
    "            cont_sent_lem = ['do' if word == 'be' else word for word in cont_sent_lem]\n",
    "    return cont_sent_lem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4cb31e0-5002-487c-b8ca-5ce012075bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prescont_to_simpress(prescont):\n",
    "    # Tokenizing\n",
    "    cont_sent_token = wt(prescont)\n",
    "    cont_sent_tag = nltk.pos_tag(cont_sent_token)\n",
    "    \n",
    "    # Lemmatizing\n",
    "    cont_sent_lem = []\n",
    "    for i in cont_sent_tag:\n",
    "        wordnet_verb = verb_to_wordnet(i[1])\n",
    "        if wordnet_verb is not None:\n",
    "            cont_sent_lem.append(lem.lemmatize(i[0], wordnet_verb))\n",
    "        else:\n",
    "            cont_sent_lem.append(i[0])\n",
    "       \n",
    "    # Correcting singular and plural\n",
    "    cont_sent_lem = correct_singular_plural(cont_sent_tag, cont_sent_lem)\n",
    "    \n",
    "    # Simple present tense form\n",
    "    print(' '.join(cont_sent_lem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cd85b41-ab60-489a-8554-7466ccb0e7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do my homework\n",
      "She studies for the exam\n",
      "John does not watch TV\n",
      "They do not stay today\n",
      "An Indian arrives in India\n",
      "South Africans win the match\n",
      "He waits for the bus\n",
      "The king kisses the queen gently\n",
      "Bees buzz around the honeycomb\n",
      "Parrots fly around the village peacefully\n",
      "A carpenter builds a bookcase\n",
      "We enjoy ourselves\n",
      "The pianist plays Fur Elise softly\n",
      "Flowers bloom in the morning\n",
      "A tree falls down in the storm\n",
      "My cousin goes to school on a bicycle\n"
     ]
    }
   ],
   "source": [
    "prescont_to_simpress(\"I am doing my homework\")\n",
    "prescont_to_simpress(\"She is studying for the exam\")\n",
    "prescont_to_simpress(\"John is not watching TV\")\n",
    "prescont_to_simpress(\"They are not staying today\")\n",
    "prescont_to_simpress(\"An Indian is arriving in India\")\n",
    "prescont_to_simpress(\"South Africans are winning the match\")\n",
    "prescont_to_simpress(\"He is waiting for the bus\")\n",
    "prescont_to_simpress(\"The king is kissing the queen gently\")\n",
    "prescont_to_simpress(\"Bees are buzzing around the honeycomb\")\n",
    "prescont_to_simpress(\"Parrots are flying around the village peacefully\")\n",
    "prescont_to_simpress(\"A carpenter is building a bookcase\")\n",
    "prescont_to_simpress(\"We are enjoying ourselves\")\n",
    "prescont_to_simpress(\"The pianist is playing Fur Elise softly\")\n",
    "prescont_to_simpress(\"Flowers are blooming in the morning\")\n",
    "prescont_to_simpress(\"A tree is falling down in the storm\")\n",
    "prescont_to_simpress(\"My cousin is going to school on a bicycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb88dc9-d6b1-43d4-8b0e-78bf8ec062af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
